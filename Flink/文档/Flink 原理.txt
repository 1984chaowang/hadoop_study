--------------Flink 原理 -----------------
1.flink是怎样保证exact-once(最重要) !
2.flink的checkpoint机制与恢复？
  为甚是要插入barrier来做checkpoint，而不是在不同算子的定时器来做checkpoint？
3.flink与storm对比怎么样？为什么要从storm迁移到flink上？
4.你在使用中怎样使用flink的？
5.源码是否已经阅读？
6.flink中其中一个节点宕机之后，怎样恢复的？？
7.flink 安全认证
8:flink怎样解决乱序问题?
9:流批系统的区别和各自优缺点?
10:Flink JobManager的HA(高可用)原理分析
11:flink的 state介绍一下
12:flink程序常见异常,怎样解决的?
13:现有开发的程序有什么不足?
14:flink 事件时间+水印+窗口 关系?什么时候会触发计算?
15:flink on yarn 原理
16:批流是怎样统一的?
17:Flink JobManagerHA ?
18:Kappa架构 && Lambda架构
19:程序优化
20:Chandy-Lamport算法

21:Flink实现风控系统
22:Flink-CEP 

23 说一下flink 常用的窗口函数
------------- 疑惑--------
增加水印时间(数据允许延迟的最大时间 maxLaggedTime) ,缓解计算压力?

水印5->120 算过来了  5->180算不过来
	AssignerWithPeriodicWatermarks,定时抽取更新
	使用的是AssignerWithPunctuatedWatermarks,每一次数据局来都会抽取更新,更精确一点,但是频繁的更新wartermark会比较影响性能

说明触发窗口计算的单个slot算子没问题,问题出在前面的打标签(是否外地车,省内外地,省外,外地长期) 耗时



数据被丢弃的问题:
     给的资源不足时,统计的数值被偏少 比如,1分钟流量 正常早晚高峰3w5+ 白天平常2w7左右
		结果少,是数据还没进来完就被触发,输出了
	另一个原因是:采集设备获取的异常数据(过车时间提前几分钟)  这种数据会提前触发窗口计算,
		后面正常时间的数据还没进来,窗口已经闭合了




1.flink是怎样保证端到端exactly-once(精确一次)?
exactly-once语义就是保证 最后数据处理的结果和数据摄入时没有数据的丢失与重复
	Flink主要是靠两个机制实现: checkpoint(检查点) 和 TwoPhaseCommitSinkFunction(两阶段提交协议)
checkpoint保证flink内部的exactly-once,不会进行重复计算
		flink的checkpoint包含了flink此时的状态 和 数据输入流的位置(kafka的offset),checkpoint
		会异步的持久化到hdfs上,如果flink应用失败或者升级时,可以拉取checkpoint中的状态来恢复上次失败时的数据

--- before ---
flink1.4版本之前实现了 输出结果是exactly-once

1.4之前的实现思路:
Flink的基本思路就是将状态定时地checkpiont到hdfs中去,当发生failure的时候恢复上一次的状态
然后将输出update到外部(注意: 输入流offset也是状态的一部分),如果发生错误 就能从最后一次状态恢复

--- after ---
flink1.4版本之后实现了 端到端的exactly-once,即输入和输出是一一对应的 没有丢失和重复
	需要kafka_0.11及以上版本(原因kafka_0.11开始支持事务)
	
1.4发布后:  两阶段提交的sink function(TwoPhaseCommitSinkFunction)
   两次提交来保证语义的方式需要flink所连接的外部系统(kafka等消息系统)支持两步提交,也就是外部系统
   需要支持可以预提交和回滚没有最终提交的数据 的特性
---------------------------------------
具体实现:

两阶段提交协议 && 预提交
	在一个分布式且含有多个并发执行sink的应用中
	单次提交或回滚不够,需要所有组件都必须对这些提交或回滚达成共识,这样才能得到一致性的结果
	
step1:两步提交协议的第一步是预提交
	  flink的jobmanager会在数据流中插入一个检查点的标记(这个标记可以用来区别这次checkpoint的数据和下次checkpoint的数据)
	  这个标记会在整个DAG中传递.每个DAG中的算子遇到这个标记就会触发这个算子状态的快照	
step2:读取kafka的算子,在遇到检查点标记时会存储kafka的offset.
	  之后会把这个检查点标记传到下一个算子 接下来就到了flink的内存操作算子这些 内部算子 就不用考虑两步提交协议了
      因为他们的状态会随着flink整体的状态来更新或者回滚
step3:到了和外部系统打交道的时候,就需要两步提交协议来保证数据不丢失不重复了.
	  在预提交这个步骤下,所有向kafka提交的数据都是预提交
step4:当所有算子的快照完成,也就是这次的checkpoint完成时,flink的jobmanager会向所有算子发通知说这次checkpoint完成.
	  flink负责向kafka写入数据的算子也会正式提交之前写操作的数据.
	  在任务运行中的任何阶段失败,都会从上一次的状态恢复,所有没有正式提交的数据也会回滚

总结一下flink的两步提交:
	当所有算子都完成他们的快照时,进行正式提交操作
	当任意子任务在预提交阶段失败时,其他任务立即停止,并回滚到上一次成功快照的状态
	在预提交状态成功后,外部系统需要完美支持正式提交之前的操作.
	如果有提交失败发生,整个flink应用会进入失败状态并重启,重启后将会继续从上次状态来尝试进行提交操作.

2.flink的checkpoint机制与恢复？
	
	
	
	
4:你在使用中怎样使用flink的?

   实时ETL(尾号限行,车辆轨迹) 
   实时数据分析(30s流量统计 高频车 重点路段/区域  流量/拥堵   在途车辆归属地分析)
   实时预警(套牌车,流量突发预警,拥堵突发预警)
kafka --> flink --> hbase(phoenix)  切换到   kafka --> flink --> kafka-->hbase(phoenix)
  数据进行聚合计算后 不是立即持久化到存储 还是先Sink到Kafka 
  原因:通过Kafka对数据落盘进行缓冲,减少直接写存储可能带来的阻塞,让流计算程序更稳定,降低背压的产生概率


7:flink安全认证

使用的kerberos+truststore
Flink证书过期  重新执行下 
	查看证书过期时间 可以通过/opt/huawei/hadoopclient/Flink/flink/test 查看 flink.keystore && flink.truststore
	这两个文件生成的时间(有效期3个月)
------------------------------------flink证书问题过期-------------------------------
如何生成truststore:  生成在conf下
	进入flink客户端的bin目录下
	sh generate_keystore.sh XXXXXX
	出现几个警告,然后提示:generate keystore/truststore success. 

#生成到/opt/huawei/hadoopclient/Flink/flink/conf目录下,同时flink-conf.yaml文件会自动填充上对应参数
	将这两个文件添加到/opt/huawei/hadoopclient/Flink/flink/test中

下载kerberos秘钥 放到服务器,在flink-conf.yaml 文件中把路径添加上 用户加上
security.kerberos.login.keytab: /opt/MtdapProgram/keytab_enjoyor/user.keytab
security.kerberos.login.principal: enjoyor

注意:文件需要分配权限 
[root@host-mn02 keytab_enjoyor]# chmod  777 krb5.conf 
[root@host-mn02 keytab_enjoyor]# chmod  777 user.keytab 

修改flink-conf.yaml配置文件中  指定认证文件:
	security.ssl.truststore: test/flink.truststore
	security.kerberos.login.keytab: /opt/MtdapProgram/keytab_enjoyor/user.keytab
	security.kerberos.login.principal: enjoyor
	security.ssl.key-password: XXXXXX
	security.ssl.keystore-password: XXXXXX
	security.ssl.keystore: test/flink.keystore

  
  

8:flink怎样解决乱序问题?

使用事件时间+水位线+窗口 详见14
通过watermark对数据重排序,来保证整体数据流的有序性
每当我们每接收到一份数据到buffer中时,我们选定其中最新的watermark值,对buffer里数据的时间小于此watermark值的数据在buffer中做一个排序.然后将此排序好的数据发向下游,因为是排好序的,所以窗口收到15:00的数据时,就知道不会有之前的数据在进来,所以水印可以作为触发计算的标识

参考:https://blog.csdn.net/Androidlushangderen/article/details/85058701



9:流批系统的区别和各自优缺点?
流系统的一大优势就是低延迟,批处理优势是错误恢复容易
批处理任务在每次的批处理操作中都会保存住全部的输入数据,如果出现算错的情况,重新执行一次处理过程即可
而流式计算中连续不断的数据处理,使得错误恢复变得复杂,Flink的错误恢复机制-CheckPoint.可以实现

某一刻任务执行失败,下一刻怎样完全恢复,重新回到失败的的时间点,任务接着跑?
A:Source的偏移量位置 offset
B:当时已经进入flink的数据
C:操作状态的数据

#flink会通过定期做checkpoint来实现A B

how checkpoint ?
在流数据中增加一个标记数据记录,barrier栅栏
barrier数据将流数据分割成多份,每份对应一次checkpoint操作,checkpoint会保留每一次的offset信息
	三分钟2个barrier,生成三个checkpoint

流:
当barrier标记从source上游流向sink下游,在接到sink端的确认消息后,此checkpoint完成
如果涉及到多个input的输入时,处理快的barrier流会等待其他流,直到它们的barrier信息到达,然后在一起往下游传输数据

#flink 使用state来实现 中间状态数据
用户可以自定义状态持久化操作,然后在应用在重新启动时,从外部存储中重新恢复状态数据

一般情况下,为了保证状态数据的一致性,checkpoint 状态数据 就是同步的过程
flink实现异步状态同步方式,实现方式:拷贝原状态的数据,然后用异步线程去持久化拷贝的那份状态
为了防止每次copy重复的状态数据,flink实现了增量的checkpoint


10:Flink JobManager的HA(高可用)原理分析

Flink的JobManager的HA 跟HDFS的HA相比 不太一样,并不仅仅是主从切换
HDFS的HA切换,主要是为了保证数据请求处理的正常服务
Flink要让所有的失败任务能够快速回复
即:一个是存储系统的HA实现  一个是计算框架的HA实现

Flink的JobManager在服务发生切换时(出现故障)要及时的通知外界事物:
	JobManager管理的多个TaskManager
	在运行的所有Job
	在请求的JobClient客户端
	
这些TaskManager,Job,JobClient收到新的leader信息,能够主动重连新的JobManager地址

源码调用过程:
Flink内部定义2类服务做HA时的领导选举和消息通知:
	LeaderElectionService  
	LeaderRetrievalService 监听端口
		LeaderRetrievalListener监听接口
在LeaderElectionService服务的实现中,是采用Apache Curator框架中的LeaderLatch来做领导选举的
新的leader选出来以后,LeaderRetrievalService服务会第一时间得到通知,然后提取出新的leader地址
然后通知监听接口LeaderRetrievalListener,通知jobclient job taskmanager


11:Flink一个任务是否是有状态的?
指的是flink内部的State的概念,不单单是指Event->State这样比较固定的概念
而是指任务运行间的数据信息,这些状态数据在容错恢复及checkpoint时将起到很关键作用

State的类型是怎样划分的? State的序列化内容? 
flink提供状态api 最底层


------- State 状态 --------
简单举例,Flink的Count聚合计算每次触发计算是将历史上所有流入的数据
重新计算一次,还是在上一次的计算结果上增量计算?
A:增量计算
那么上一次计算的结果保存在哪里,内存中可以吗?
如果保存到内存中 由于网络硬件等原因造成某个计算节点失败的情况下,上一次计算结果会丢失
在节点恢复的时候，就需要将历史上所有数据（可能十几天，上百天的数据）重新计算一次
为避免这种情况,flink 会利用State存储计算结果

State是指流计算过程中计算节点的 中间计算结果 或 元数据属性
	在aggregation过程中要在state中记录中间聚合结果
	Kafka 作为数据源时候，我们也要记录已经读取记录的offset,这些State数据在计算过程中会进行持久化(插入或更新)
所以Apache Flink中的State就是与时间相关的,Apache Flink任务的内部数据(计算数据和元数据属性)的快照
	
Why state?
	1:与批计算相比,State是流计算特有的,批计算没有failover机制,要么成功,要么重新计算
	2:流计算在 大多数场景 下都是增量计算,数据逐条处理（大多数场景),每次计算是在上一次计算结果之上进行处理的
	  这样的机制势必要将上一次的计算结果进行存储（生产模式要持久化），
	3:另外由于 机器/网络/脏数据等原因导致的程序错误
	  在重启job时候需要从成功的检查点进行state的恢复。增量计算，Failover这些机制都需要state的支撑





12:flink程序常见异常,怎样解决的?

出现最多的问题就是反压,交通业务卡口数据,早晚高峰时产生,下游的处理速度跟不上上游消费kafka的速度

猜测的原因:大量的计算指标 13个指标  算不过来  流控 
		  窗口算子使用的timeWindowAll 非并行算子  只能一个slot
	反压产生在source,数据最终都会被积压在发生反压上游的算子的本地缓冲区(localbuffer)中
	每一个taskmanager都有一个本地缓冲池,每一个算子数据进来后都会把数据填充到本地缓冲池中,
	数据从这个算子出去后会回收这块内存,但是当被反压后,数据发不出去,本地缓冲池就无法释放,导致一直请求缓冲区(requestBuffer).
解决:调大等待时延120s-->180s  12个slot   60s算一次,窗口被触发的时间延迟了 
	或者是任务拆分,将流量统计跟外地车拆分开 
	//TODO  专门写一个流量统计 最低资源跑一下 1slot + 30s+5s延迟
	slot 内存隔离,CPU不隔离
实际原因:线上CPU负载高,CPU争夺导致
	产生过两次,一次是集群中solr数据量超过规划导致,50亿数据查询导致GC频繁
	一次是离线任务:伴随车计算 分时段并行跑导致 
	实时离线程序,以及跟solr 未隔离导致的  
	
另一个数据质量问题:
卡口设备采集到的过车时间 会提前或者滞后
	网络传输/设备故障问题 会导致今天过车数据明天才会到达

过车时间提前(脏数据) 会导致计算窗口被提前触发-结束,数据失真  逻辑上需要过滤掉这部分数据

还有CPU指定的太小,且CPU不隔离  导致CPU在高峰期计算紧张 造成滞后



13:现有程序的不足
多个任务在一个yarn-cluster上,一个taskmanager上可能会有多个task,会发生CPU资源争夺
实时离线程序 没有进行任务隔离
这种情况一般会在CPU负载高的情况下产生 (solr单表数据量太大,频繁GC  另一个是离线程序MR 并发时产生)





14:flink 事件时间+水印+窗口 关系?什么时候会触发计算?

以在途车辆归属地分析这个功能为例.使用事件时间+水印抽取+时间取余规整 5分钟一次 +滚动窗口5分钟
9:15分就出9:10-9:15的结果  程序刚执行1分钟,就被触发输出结果了 可以得出:设置5分钟计算窗口 并不是程序运行5分钟后第一批数据才会输出
触发的时间,是取余后的水印时间+最大延时5s
所以窗口触发的时间并不是程序执行5分钟才算第一次,是按照五分钟划分一个窗口 只要水印中出现窗口结束的那个时间,就会触发窗口计算
	中间会对数据进行排序! (数据是存放在堆内存中的) 
	一批数据进来 进到已经划分好的窗口中 进行排序 当期间出现窗口结束时间的那条数据,窗口闭合 后续数据被抛弃 触发计算 输出

顺便解决一个疑惑:
	程序刚发布时,会出现大量历史过车时间的汇总数据? 比如:2019-9-12 09:43:00发布,出现 大批 2019-09-11 XX:XX:XX  甚至更久数据
	原因就是,数据质量不高(脏数据) 出现的错误过车时间的日志,这些过车时间 被抽取成水印时间 然后再加上等待的5s 后续数据已经到达,
	触发窗口的计算规则就输出了
	处理:这些数据过滤掉




15:flink on yarn
Client提交App到RM上面去运行，然后RM分配第一个container去运行AM，然后由AM去负责资源的监督和管理。
需要说明的是，Flink的yarn模式更加类似spark on yarn的cluster模式，在cluster模式中，dirver将作为AM中的一个线程去运行，
在Flink on yarn模式也是会将JobManager启动在container里面，去做个driver类似的task调度和分配，
YARN AM与Flink JobManager在同一个Container中，这样AM可以知道Flink JobManager的地址，
从而AM可以申请Container去启动Flink TaskManager。待Flink成功运行在YARN集群上，
Flink YARN Client就可以提交Flink Job到Flink JobManager，并进行后续的映射、调度和计算处理。


16:批流是怎样统一的?
Batch和streaming会有两个不同的ExecutionEnvironment,不同的ExecutionEnvironment会将不同的API翻译成不同的JobGgrah,
JobGraph 之上除了 StreamGraph 还有 OptimizedPlan.OptimizedPlan 是由 Batch API 转换而来的.
StreamGraph 是由 Stream API 转换而来的,JobGraph 的责任就是统一 Batch 和 Stream 的图.


17:Flink JobManagerHA ?
与Storm不同的是，知道Storm在遇到异常的时候是非常简单粗暴的，
比如说有发生了异常，可能用户没有在代码中进行比较规范的异常处(至少执行一次)的语义，
比如说一个网络超时的异常对他而言影响可能并没有那么大，
但是Flink不同的是他对异常的容忍度是非常的苛刻的，那时候就考虑的是比如说会发生节点或者是网络的故障，
那JobManager单点问题可能就是一个瓶颈，JobManager那个如果挂掉的话，
那么可能对整个作业的影响就是不可恢复的，所以考虑了做HA



18:Kappa架构
用来解决lambda架构的不足,即更多的开发和运维工作
lambda架构背景是流处理引擎还不完善,流处理的结果只作为临时的、近似的值提供参考
Flink流处理引擎出现后,为了解决两套代码的问题,Kappa架构出现

Kappa架构介绍:
	Kappa 架构可以认为是 Lambda 架构的简化版（只要移除 lambda 架构中的批处理部分即可）
	在 Kappa 架构中，需求修改或历史数据重新处理都通过上游重放完成。
	Kappa 架构最大的问题是流式重新处理历史的吞吐能力会低于批处理，但这个可以通过增加计算资源来弥补。

调研:flink可以保证计算的准确性,但是有一个前提是数据时准时到达的.
	卡口过车数据 设备会因为网络延迟迟到几个小时,所以 Kappa架构不适合我们
	建议次日凌晨使用离线计算统计前天数据,替换实时表数据

Lambda架构:

Lambda 架构用定期运行的批处理作业来实现应用程序的持续性，并通过流
处理器获得预警。流处理器实时提供近似结果；批处理层最终会对近似结果予以纠正

批处理架构很难解决乱序事件流问题
批处理作业的界限不清晰,写死了 假设需要根据产生数据的时间段(如从用户登录到退出)生成
聚合结果，而不是简单地以小时为单位分割数据

	
	
19:集群CPU负载高 会影响Flink 及Solr查询 
 产生原因 solr单表数据量太大(50亿/65字段/25索引字段) 并发查询时,垃圾回收不及时
 影响: solr查询慢,flink 任务进行CPU争夺 数据滞后
 解决方式: 数据分表 分为实时表和历史表 实时表保持在20亿左右,数据定期删除

20:Chandy-Lamport算法

将流计算看作成一个流式的拓扑,定期在这个拓扑的头部source点开始插入特殊的barriers(栅栏)
从上游开始不断向下游广播这个Barriers.
每一个节点收到所有的barriers,会将state做一次snapshot(快照)
当每个节点都做完Snapshot之后,整个拓扑就算做完一次checkpoint
接下来不管出现任何故障,都会从最近的checkpoint进行恢复

Flink用这套算法,保证了强一致性的语义,
	也是Flink区别于其他无状态流计算引擎的核心区别






21:Flink实现风控系统
参考:https://mp.weixin.qq.com/s/RnUnMtlm4M6nPvjvmo8HWw
flink+规则引擎实现实时风控解决方案

互联网产品,典型的风控场景:
	注册风控、登陆风控、交易风控、活动风控 
达到事前预警,事中控制的效果

# 业务系统 风控系统 惩罚系统 分析系统
业务系统:通常是 APP + 后台 或者 web,是互联网业务的载体,风险从业务系统触发
风控系统:为业务系统提供支持,根据业务系统传来的数据 或 埋点信息来判断当前用户 或 事件有无风险
惩罚系统:业务系统 根据风控系统的结果 来调用,对有风险的用户或事件进行控制 或 惩罚 
		 比如增加验证码、限制登陆、禁止下单等等
分析系统:根据数据来衡量风控系统的表现:
		 比如某策略拦截率突然降低,那可能意味着该策略已经失效,
		 又比如活动商品被抢完的时间突然变短,这表明总体活动策略可能有问题等等,
		 该系统也应支持运营/分析人员发现新策略

风控系统 && 分析系统
业务场景: 电商业务
风控范围: 注册(虚假/批量注册) 登录(盗号登陆) 交易(盗刷客户余额) 活动(薅羊毛)
风控实现方案：事中风控 --> 目标为拦截异常事件

风控系统:规则 && 模型 两种技术路线
	规则:简单直观、可解释性强、灵活 缺点:容易被攻破,一但被黑产猜中就会失效
		 实际的风控系统中,往往需要再结合上基于模型的风控环节来增加健壮性

规则可以组合成规则组

//TODO

22:Flink-CEP 
CEP的规则解析之后,本质上是一个不确定状态的转换机,所以在匹配过程中:每个状态会对应着一个或多个元素








23 说一下flink 常用的窗口函数
ReduceFunction  AggregateFunction FoldFunction  ProcessWindowFunction
前两个函数执行效率更高,因为 Flink 可以在每个窗口中元素到达时增量地聚合
ProcessWindowFunction 将获得一个窗口内 所有元素的迭代器 以及 元素所在窗口的 附加元信息
	  .timeWindow(Time.seconds(10)) //这里的时间窗口用于保证从外部接收当前批次的所有数据，不宜过小
      .process(new KeyAreaIndexProcessFunction) //(重点区域编码,计算时间,时间标识,区域拥堵指数)
注意:	
	使用 ProcessWindowFunction 的窗口转换操作不能像其他那样有效率
	是因为 Flink 在调用该函数之前 必须在内部缓存窗口中 的所有元素
  A:这可以通过将 ProcessWindowFunction 与 ReduceFunction， AggregateFunction 或 FoldFunction 
	组合使用来获得窗口元素的 增量聚合 以及 WindowFunction接收的附加窗口元数据








99:备注
source的并行度设置的算子并行度>kafka的分区数 可以,但是多的获取不到数据   

